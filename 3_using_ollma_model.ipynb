{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Running Jupyter Code with Ollama Server**\n",
    "\n",
    "1. **Download and Install Ollama**: Ensure that Ollama is downloaded and installed on your system.\n",
    "\n",
    "2. **Check Ollama Version**:\n",
    "   ```bash\n",
    "   ollama --version\n",
    "   ```\n",
    "\n",
    "3. **Run Llama 3.2 Model**:\n",
    "   To load the Llama 3.2 model:\n",
    "   ```bash\n",
    "   ollama run llama3.2\n",
    "   ```\n",
    "\n",
    "4. **Start Ollama Server**:\n",
    "   To start the Ollama server, run:\n",
    "   ```bash\n",
    "   ollama serve\n",
    "   ```\n",
    "\n",
    "**Note**: If you face any issues while running the server, checking the background tasks using the port can help resolve conflicts. Always ensure the port is free before starting the server.\n",
    "\n",
    "1. **Check if Ollama Server is Running**:\n",
    "   Check if the server is running and using port 11434:\n",
    "   ```bash\n",
    "   netstat -ano | findstr :11434\n",
    "   ```\n",
    "\n",
    "2. **Identify and Kill Background Task (if needed)**:\n",
    "   If you see that another task is using the port, you can identify and kill it:\n",
    "   ```bash\n",
    "   tasklist /FI \"PID eq <PID>\"\n",
    "   taskkill /PID <PID> /F\n",
    "   ```\n",
    "\n",
    "3. **Close Ollama from Windows Task Bar (Optional)**:\n",
    "   If the server is still not responding or you see issues, you can use the **up arrow key** (^) on the Windows task bar (bottom-left) to close any running Ollama instances.\n",
    "\n",
    "4. **Start Jupyter Notebook**:\n",
    "   Once the server is running, start your Jupyter notebook with the necessary code to interact with Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''You are an agent which analyses the resume and understands the context of resume and \n",
    "    extract the following fields and format the output:\n",
    "    - Name\n",
    "    - Email\n",
    "    - Phone 1\n",
    "    - Phone 2\n",
    "    - Address\n",
    "    - City\n",
    "    - LinkedIn\n",
    "    - Professional Experience (in years)\n",
    "    - Highest Education\n",
    "    - Is Fresher (yes/no)\n",
    "    - Is Student (yes/no)\n",
    "    - Skills (comma-separated)\n",
    "    - Applied For Profile\n",
    "    - Education (Institute Name, Year of Passing, Score)\n",
    "    - Projects (Project Name, Description)\n",
    "    - Professional Experience (Organisation Name, Duration, Profile)\n",
    "\n",
    "    Ensure to format the output as:\n",
    "    Name: [Value]\n",
    "    Email: [Value]\n",
    "    Phone 1: [Value]\n",
    "    ... and provide this summary of resume in markdown format'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()  # Extract text from each page\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "    return text\n",
    "    \n",
    "user_prompt = extract_text_from_pdf('./data/python-developer-resume-example.pdf') + \"Provide a summary of this resume\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response: ### Resume Summary\n",
      "\n",
      "#### Contact Information\n",
      "\n",
      "* **Name:** G I U L I A\n",
      "* **Email:** `ggonzalez@email.com`\n",
      "* **Phone 1:** `(123) 456-7890`\n",
      "\n",
      "#### Address and Social Media\n",
      "\n",
      "* **Address:** Detroit, MI\n",
      "* **City:** Detroit, MI\n",
      "* **LinkedIn:** LinkedIn\n",
      "* **Github:** Github\n",
      "\n",
      "#### Education\n",
      "\n",
      "* **Highest Education:** M.S. in Computer Science from University of Chicago (2014 - 2016)\n",
      "* **Previous Education:**\n",
      "\t+ B.S. in Computer Science from University of Pittsburgh (2010 - 2014)\n",
      "\n",
      "#### Work Experience and Skills\n",
      "\n",
      "* **Professional Experience:** Python Developer\n",
      "\t+ Duration: September 2017 - current at DoorDash (Detroit, MI)\n",
      "\t+ Summary:\n",
      "\t\t- Improved time on page for the average user by 2 minutes\n",
      "\t\t- Reduced customer complaints by 23%\n",
      "\t\t- Boosted revenue by 6%\n",
      "* **Skills:** HTML/ CSS, SQL (PostgreSQL, Oracle), JavaScript (Angular), Python (Django), REST APIs (GraphQL), AWS (Redshift, S3), Git\n",
      "\n",
      "#### Work Experience Details\n",
      "\n",
      "* **Python Developer Intern**\n",
      "\t+ Institution: Knewton\n",
      "\t+ Duration: April 2016 - April 2017 (Chicago, IL)\n",
      "\t+ Summary:\n",
      "\t\t- Implemented RESTful APIs in Django for internal analytics team\n",
      "\t\t- Reduced bugs reported by the client by 11% month over month\n",
      "\n",
      "#### Projects\n",
      "\n",
      "* **Cryptocurrency Price Tracker**\n",
      "\t+ Description: Creator of a project that incorporated API calls to several applications and stored data efficiently in PostgreSQL backend.\n",
      "\t+ Technologies Used: D3.js, PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://localhost:11434/api/chat\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Define the conversation prompt and specify the model\n",
    "data = {\n",
    "    \"model\": \"llama3.2\",  # Specify the model name here\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Send the POST request to the Ollama server\n",
    "response = requests.post(url, json=data, headers=headers, stream=True)\n",
    "\n",
    "# Check if the response is successful\n",
    "if response.status_code == 200:\n",
    "    # Initialize a variable to accumulate the assistant's response\n",
    "    full_response = \"\"\n",
    "    \n",
    "    # Iterate over the chunks of data as they arrive\n",
    "    for chunk in response.iter_lines():\n",
    "        if chunk:  # Ignore empty lines\n",
    "            try:\n",
    "                # Each chunk is a part of the message, so we can parse it as JSON\n",
    "                chunk_data = json.loads(chunk.decode('utf-8'))\n",
    "                \n",
    "                # Extract the message content\n",
    "                message_content = chunk_data.get('message', {}).get('content', '')\n",
    "                full_response += message_content\n",
    "                \n",
    "                # Check if the response is done\n",
    "                if chunk_data.get('done', False):\n",
    "                    break\n",
    "                \n",
    "            except json.JSONDecodeError as e:\n",
    "                print(\"Error parsing JSON chunk:\", e)\n",
    "    \n",
    "    print(\"Model Response:\", full_response)\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
